---
layout: post
title: AGI 직전이라더니 내가 사용하는 AI는 왜 멍청할까?
author: 'Juho'
date: 2025-04-30 09:00:00 +0900
categories: [LLM]
tags: [LLM, Benchmark, AI, Python]
pin: True
toc : True
---

<style>
  th{
    font-weight: bold;
    text-align: center;
    background-color: white;
  }
  td{
    background-color: white;
  }

</style>

## 목차
1. [벤치마크 점수와 사용자의 체감은 다르다](#벤치마크-점수와-사용자의-체감은-다르다)
2. [벤치마크 점수의 함정](#벤치마크-점수의-함정)

## 벤치마크 점수와 사용자의 체감은 다르다
최신 AI 모델들은 매번 기록적인 벤치마크 점수를 달성하고 제조사들은 "AGI 직전 단계"라는 표현까지 사용합니다.  
그러나 실제로 이러한 모델들을 사용해보면 기대에 미치지 못하는 경우가 많습니다.  
왜 제조사가 홍보하는 성능 지표와 실제 사용 경험 사이에 이렇게 큰 간극이 존재하는 걸까요?  

## 벤치마크 점수의 함정
### 제조사들은 바보가 아니다
제조사들은 GLUE, SuperGLUE, MMLU, HumanEval 같은 널리 알려진 벤치마크에서 최고 점수를 얻기 위해 하이퍼파라미터 조정, 학습 데이터 추가, 다양한 기법 적용 등 모든 수단을 동원합니다.  
이러한 최적화는 "실제 사용 시나리오"보다 "벤치마크 통과"에 초점을 맞추게 되어 실제 대화나 응용 프로그램에서는 과적합된 성능을 보이는 경우가 많습니다.  
"○○점 돌파"라는 보도자료 한 줄이 투자 유치, 고객 신뢰, 시장 점유율에 결정적 영향을 미치는 현실에서 벤치마크 점수 경쟁은 생존 경쟁과도 같습니다.  
제조사의 벤치마크 결과 자체는 거짓은 아닙니다. 해당 벤치마크로 테스트하면 누구나 재현하여 검증할 수 있기 때문입니다.  
하지만 이 점수가 일상적인 사용 경험에서도 우수한 성능을 보장하지는 않습니다.  
  
    
### 벤치마크와 실제 사용과의 간극
벤치마크는 통제된 환경에서 특정 작업의 수행 능력을 측정할 뿐 실제 세계의 복잡성과 예측 불가능성을 온전히 반영하지 못합니다.  
1) 테스트 데이터와 실제 데이터의 차이  
벤치마크 데이터셋은 특정 도메인, 형식, 사전 정의된 문제 유형으로 구성되어 있습니다.  
반면 현실의 데이터는 언어 표현, 문맥, 오타 등의 패턴이 훨씬 다양하고 예측 불가능합니다.  
  
2) 정해진 규칙 vs. 자유로운 대화  
벤치마크에서는 대부분 정답이 하나로 정해진 과제가 주어지지만 실제 대화나 작업에서는 정답이 명확하지 않고 모호함을 적절히 다루는 능력이 중요합니다.  
  
3) 실제 과제의 높은 복잡성  
창의적 콘텐츠 생성, 다단계 추론, 사용자 맞춤형 피드백 등 실제 사용 환경에서 마주하는 과제들은 벤치마크보다 훨씬 더 높은 복잡성과 유연성을 요구합니다.  
  
  
### 성공 사례만 공개하고 실패 사례는 숨긴다  
벤치마크는 평균 성능만 보여주므로 fail-case는 잘 드러나지 않습니다.  
사용자 경험을 크게 해치는 환각, 맥락 무시, 논리적 오류 등은 공개되지 않는 경향이 있습니다.  
그래서 최근에는 벤치마크 점수나 리더보드에 대한 무용론까지 나오는 것 같습니다.  



---  
  

다양한 AI를 사용해보고 주로 하는 업무, 대화 스타일에 맞는 모델을 찾는것이 중요할 것 같습니다.  
AGI 직전이라고 해도 결국 우리 손에 쥐어진 AI는 ‘특정 목적에 최적화된’ AI일 뿐이니까요.  
