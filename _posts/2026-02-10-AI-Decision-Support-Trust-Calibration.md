---
layout: post
title: AI 의사결정지원 시스템이 실패하는 진짜 이유 - 신뢰 보정의 부재
author: 'Juho'
date: 2026-02-10 01:00:00 +0900
categories: [AI]
tags: [AI, LLM, UX]
pin: True
toc: True
---

<style>
  th{
    font-weight: bold;
    text-align: center;
    background-color: white;
  }
  td{
    background-color: white;
  }
</style>

## 목차
1. [개요](#개요)
2. [AI 의사결정지원 시스템의 실패 양상](#ai-의사결정지원-시스템의-실패-양상)
3. [신뢰의 본질 재정의](#신뢰의-본질-재정의)
4. [Trust vs Trustworthiness의 구분](#trust-vs-trustworthiness의-구분)
5. [설명가능성(XAI)의 역할](#설명가능성xai의-역할)
6. [신뢰 보정을 위한 5단계 실행 방안](#신뢰-보정을-위한-5단계-실행-방안)
7. [설계자의 관점 전환](#설계자의-관점-전환)
8. [정리](#정리)
9. [Reference](#reference)

## 개요

AI 기반 의사결정지원 시스템(DSS)이 현장에서 작동하지 못하는 이유는 무엇일까?
많은 사람들이 "모델 성능이 부족해서"라고 생각하지만, 실제 원인은 다른 곳에 있다.
해경닷컴에서 발표한 분석에 따르면, AI DSS 실패의 근본 원인은 **신뢰 보정(Trust Calibration)의 부재**다.

## AI 의사결정지원 시스템의 실패 양상

AI DSS가 현장에서 실패하는 양상은 크게 세 가지로 나타난다.

### 미사용 (Disuse)

사용자가 시스템을 무시하거나 우회하는 현상이다.
아무리 정확한 AI라도 사용자가 신뢰하지 않으면 활용되지 않는다.

### 오남용 (Misuse)

과신으로 인한 사고 발생이다.
AI 추천을 맹목적으로 따르다가 중대한 오류가 발생하는 경우다.

### 남용 (Abuse)

책임 회피 수단으로 AI를 활용하는 것이다.
"AI가 그렇게 말했으니까"라는 핑계로 책임을 전가한다.

## 신뢰의 본질 재정의

여기서 중요한 점은 신뢰를 어떻게 정의하느냐다.
신뢰는 단순한 감정이나 사용 경험의 문제가 아니다.

신뢰는 **리스크 상황에서 예측을 가능하게 하는 메커니즘**이자 **계약**이다.
두 가지 요소가 결합될 때만 신뢰가 의미를 갖는다.

- **취약성(Vulnerability)**: 손해 가능성이 존재해야 한다
- **예측(Predictability)**: 시스템이 예상대로 작동할 것이라는 기대가 있어야 한다

모든 신뢰는 암묵적 계약을 포함한다.
이 계약에는 정확성, 강건성, 공정성, 투명성, 책임성 같은 구체적 특성들이 포함된다.

## Trust vs Trustworthiness의 구분

여기서 핵심적인 구분이 필요하다.

- **신뢰(Trust)**: 사용자의 태도
- **신뢰할 만함(Trustworthiness)**: 시스템의 능력

사용자는 AI를 무조건 믿지 않는다.
정확성, 공정성, 책임성 같은 구체적 특성을 믿는다.
이러한 계약과 한계를 명시하지 않으면 문제가 발생한다.

UI 디자인이나 권위감이 부당한 신뢰를 조성하면 오남용으로 이어진다.
반대로 불필요한 의심을 유발하면 미사용으로 이어진다.

"신뢰를 높이자"라는 단순한 접근이 오히려 과도한 의존을 유발할 수 있다는 점도 경고한다.

## 설명가능성(XAI)의 역할

설명가능한 AI(XAI)에 대한 오해도 있다.
XAI의 목적은 신뢰를 "증폭"하는 것이 아니다.

XAI는 과도한 의존과 과도한 의심 사이의 **균형을 유지**하는 데 기여한다.
적절한 수준의 설명은 사용자가 언제 AI를 믿고, 언제 의심해야 하는지 판단하는 데 도움을 준다.

## 신뢰 보정을 위한 5단계 실행 방안

해경닷컴은 신뢰 보정을 위한 구체적인 5단계 실행 방안을 제시한다.

### 1단계: 계약을 명시적으로 문장화

AI 시스템이 사용자에게 제공하는 약속을 명확하게 문서화한다.
"이 시스템은 X 상황에서 Y 정확도로 Z를 예측한다"처럼 구체적으로 작성한다.

### 2단계: 취약성 분석표 작성

사용자가 AI를 잘못 신뢰했을 때 발생할 수 있는 손해를 분석한다.
잠재적 위험 시나리오를 체계적으로 정리한다.

### 3단계: 능력-한계 분리 기록

AI가 잘하는 것과 잘하지 못하는 것을 명확히 구분한다.
한계를 숨기지 않고 투명하게 공개한다.

### 4단계: UX 설계 원칙 적용

확신 표현을 최소화한다.
경계 조건을 강조한다.
AI가 불확실할 때 이를 명확히 표시한다.

### 5단계: 의존/의심/폴백 장치 구축

사용자가 AI에 과도하게 의존하지 않도록 장치를 마련한다.
적절한 의심을 유도하는 메커니즘을 설계한다.
AI가 실패할 때를 대비한 폴백 장치를 구축한다.

## 설계자의 관점 전환

AI DSS 설계자는 질문 자체를 바꿔야 한다.

**기존 질문**: "신뢰를 어떻게 올릴까?"

**새로운 질문**: "무엇을 믿게 하고, 언제 의심하게 할 것인가?"

이 관점 전환이 핵심이다.
계약, 취약성, 보정 중심의 설계가 필수다.

## 정리

AI 의사결정지원 시스템의 성공은 모델 성능만으로 결정되지 않는다.
사용자가 시스템을 적절히 신뢰하고 활용하는 것이 핵심이다.

목표는 신뢰 증가가 아니다.
**정당한 신뢰와 정당한 불신의 보정**이 목표다.

사용자가 AI를 믿어야 할 때 믿고, 의심해야 할 때 의심하도록 설계해야 한다.
이것이 AI DSS가 현장에서 실제로 작동하게 만드는 방법이다.

## Reference

- [AI 의사결정지원(DSS)이 현장에서 작동하지 못하는 진짜 이유](https://www.haegyung.com/ko-ai-decision-support-trust/)
