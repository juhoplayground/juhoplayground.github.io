---
layout: post
title: Kimi K2.5 - Moonshot AI의 1조 파라미터 오픈 웨이트 멀티모달 모델
author: 'Juho'
date: 2026-02-01 00:00:00 +0900
categories: [AI]
tags: [AI, LLM, MoE, Agent, Benchmark]
pin: True
toc: True
---

<style>
  th{
    font-weight: bold;
    text-align: center;
    background-color: white;
  }
  td{
    background-color: white;
  }
</style>

## 목차
1. [개요](#개요)
2. [Kimi K2.5란?](#kimi-k25란)
3. [모델 아키텍처](#모델-아키텍처)
4. [주요 기능](#주요-기능)
5. [벤치마크 성능](#벤치마크-성능)
6. [Agent Swarm](#agent-swarm)
7. [사용 방법](#사용-방법)
8. [배포 및 접근성](#배포-및-접근성)
9. [Reference](#reference)

## 개요

중국 AI 기업 Moonshot AI가 2026년 1월 27일 Kimi K2.5를 공개했다.
Kimi K2.5는 1조(1T) 파라미터 규모의 Mixture-of-Experts(MoE) 아키텍처 기반 오픈 웨이트 멀티모달 모델이다.
GPT-5.2, Claude Opus 4.5 등과 25개 이상의 벤치마크에서 비교 평가되었으며, 다수의 항목에서 경쟁력 있는 성능을 보여주었다.
특히 HLE-Full(도구 활용 포함) 벤치마크에서 50.2%로 GPT-5.2(45.5%)를 상회하는 결과를 기록했다.
Modified MIT License로 (https://huggingface.co/moonshotai/Kimi-K2.5){:target="_blank"}에서 모델 가중치와 코드가 공개되어 있다.

## Kimi K2.5란?

Kimi K2.5는 Moonshot AI의 첫 번째 플래그십 멀티모달 모델이다.
2025년 11월에 공개된 Kimi K2-Base를 기반으로, 약 15조(15T) 개의 비전 및 텍스트 혼합 토큰으로 추가 사전학습(continued pretraining)을 수행했다.
일반 추론, 비주얼 코딩, 에이전트 도구 호출 등에서 우수한 성능을 제공한다.

기존 오픈 웨이트 모델들이 텍스트 위주였던 것과 달리, Kimi K2.5는 이미지와 비디오를 네이티브로 지원하는 멀티모달 모델이라는 점이 차별점이다.
Standard 모드와 Thinking 모드 두 가지 추론 모드를 지원하여 상황에 따라 품질과 속도를 조절할 수 있다.

## 모델 아키텍처

Kimi K2.5의 아키텍처 상세 사양은 다음과 같다.

### 모델 사양

| 구성 요소 | 사양 |
|----------|------|
| 아키텍처 | Mixture-of-Experts (MoE) |
| 총 파라미터 | 1T (1조) |
| 활성 파라미터 | 32B |
| 레이어 수 | 61 (Dense 레이어 1개 포함) |
| Attention Hidden Dimension | 7168 |
| MoE Hidden Dimension (Expert당) | 2048 |
| Attention Head 수 | 64 |
| Expert 수 | 384 |
| 토큰당 선택 Expert 수 | 8 |
| 공유 Expert | 1 |
| 어휘 크기 | 160K |
| 컨텍스트 길이 | 256K 토큰 |
| Attention 메커니즘 | MLA (Multi-head Latent Attention) |
| 활성화 함수 | SwiGLU |
| 비전 인코더 | MoonViT (400M 파라미터) |
| 양자화 | Native INT4 |
| 저장 용량 | 약 595GB |

MoE 아키텍처를 채택하여 384개의 Expert 중 토큰당 8개만 활성화한다.
이를 통해 총 1조 파라미터 규모이지만 실제 추론 시에는 320억 파라미터만 사용하여 하드웨어 비용을 크게 절감한다.
Muon 알고리즘을 사용하여 히든 레이어를 가속화하고 성능을 향상시켰다.
또한 병렬화된 Attention(Parallelized Attention) 방식을 적용하여 순차 처리 대신 동시 처리로 추론 속도를 높였다.

비전 인코더로는 4억 파라미터 규모의 MoonViT을 탑재하여 이미지, 차트, 비디오 등 다양한 시각 데이터를 처리한다.
Native INT4 정밀도로 배포되어 FP8/BF16 대비 메모리 효율이 높다.

## 주요 기능

### 네이티브 멀티모달 지원

Kimi K2.5는 약 15조 개의 비전-텍스트 혼합 토큰으로 사전학습되어 이미지, 차트, 비디오를 네이티브로 처리한다.
별도의 어댑터 없이 시각적 입력을 직접 이해하고 응답할 수 있다.

### 비주얼 코딩

UI 디자인, 비디오 워크플로 등 시각적 명세로부터 코드를 직접 생성할 수 있다.
비전 입력을 바탕으로 코드를 작성하는 비주얼 코딩 능력은 오픈 웨이트 모델 중 최고 수준이다.

### 듀얼 모드 추론

- Thinking 모드 : 복잡한 추론이 필요한 작업에서 더 높은 품질의 출력을 생성한다. 권장 파라미터는 temperature=1.0, top_p=0.95이다.
- Instant 모드 : 빠른 응답이 필요한 경우에 사용한다. 권장 파라미터는 temperature=0.6, top_p=0.95이다.

### 낮은 환각률

Kimi K2.5는 AA-Omniscience Index에서 -11점을 기록했다.
환각률이 64%로 낮은 수준이며, 불확실한 정보에 대해서는 답변을 생성하기보다 응답을 보류하는 경향이 있다.

### 토큰 효율성

벤치마크 전반에서 약 8,200만 개의 추론 토큰을 사용하여, Kimi K2 Thinking(약 9,500만 토큰) 대비 낮은 토큰 소비량을 보여준다.

## 벤치마크 성능

Kimi K2.5는 GPT-5.2, Claude Opus 4.5 등과 25개 이상의 벤치마크에서 비교 평가되었다.

### 추론 및 지식

| 벤치마크 | 점수 |
|----------|------|
| AIME 2025 | 96.1% |
| HMMT 2025 | 95.4% |
| GPQA-Diamond | 87.6% |
| MMLU-Pro | 87.1% |
| HLE-Full (도구 활용) | 50.2% |

HLE-Full은 수학, 물리학 등을 포함한 2,500개의 난이도 높은 문제로 구성된 벤치마크로, Kimi K2.5가 오픈 웨이트 모델 중 최고 점수를 기록했다.

### 비전 및 멀티모달

| 벤치마크 | 점수 |
|----------|------|
| MMMU-Pro | 78.5% |
| OCRBench | 92.3% |
| VideoMMMU | 86.6% |
| VideoMME | 87.4% |
| MathVista (mini) | 90.1% |

### 코딩

| 벤치마크 | 점수 |
|----------|------|
| SWE-Bench Verified | 76.8% |
| SWE-Bench Pro | 50.7% |
| LiveCodeBench (v6) | 85.0% |
| Terminal Bench 2.0 | 50.8% |

### 에이전트 검색

| 벤치마크 | 점수 |
|----------|------|
| BrowseComp (Agent Swarm) | 78.4% |
| WideSearch (Agent Swarm) | 79.0% |
| DeepSearchQA | 77.1% |

GDPval-AA 평가에서 Elo 1309를 기록하여 오픈 웨이트 모델 중 최고 수준을 달성했다.
이전 오픈 웨이트 리더였던 GLM-4.7에 대해 66%의 승률을 보였다.

## Agent Swarm

Kimi K2.5의 핵심 기능 중 하나는 Agent Swarm이다.
Agent Swarm은 복잡한 작업을 단순한 하위 단계로 분할하고, 각 하위 단계를 별도의 AI 에이전트에 할당하는 자기 주도적(self-directed) 협업 시스템이다.

### 동작 방식

1. 사용자가 복잡한 작업을 요청한다.
2. Kimi K2.5가 작업을 분석하여 하위 작업들로 분할한다.
3. 각 하위 작업에 특화된 도메인별 에이전트를 동적으로 생성한다.
4. 내장된 오케스트레이션 엔진이 프롬프트당 최대 100개의 에이전트를 생성하고 관리한다.
5. 각 에이전트가 병렬로 작업을 수행하고 결과를 통합한다.

이 방식은 기존의 단일 에이전트 접근 방식 대비 복잡한 검색이나 분석 작업에서 높은 성능을 보여준다.
BrowseComp에서 78.4%, WideSearch에서 79.0%의 점수가 이를 증명한다.

## 사용 방법

Kimi K2.5는 OpenAI 호환 API를 통해 사용할 수 있다.

### Thinking 모드

```python
import openai

client = openai.OpenAI(api_key="your_api_key")

messages = [
    {
        'role': 'system',
        'content': 'You are Kimi, an AI assistant created by Moonshot AI.'
    },
    {
        'role': 'user',
        'content': [
            {
                'type': 'text',
                'text': 'which one is bigger, 9.11 or 9.9? think carefully.'
            }
        ],
    },
]

response = client.chat.completions.create(
    model="kimi-k2.5",
    messages=messages,
    max_tokens=4096
)

print(f'Reasoning: {response.choices[0].message.reasoning_content}')
print(f'Response: {response.choices[0].message.content}')
```

### Instant 모드

```python
response = client.chat.completions.create(
    model="kimi-k2.5",
    messages=messages,
    max_tokens=4096,
    extra_body={'thinking': {'type': 'disabled'}}
)
```

### 이미지 입력

```python
import base64
import requests

url = 'https://example.com/image.png'
image_base64 = base64.b64encode(requests.get(url).content).decode()

messages = [
    {
        'role': 'user',
        'content': [
            {'type': 'text', 'text': 'Describe this image in detail.'},
            {
                'type': 'image_url',
                'image_url': {
                    'url': f'data:image/png;base64,{image_base64}'
                },
            },
        ],
    }
]

response = client.chat.completions.create(
    model="kimi-k2.5",
    messages=messages,
    max_tokens=8192
)
```

### 비디오 입력

```python
import base64
import requests

url = 'https://example.com/video.mp4'
video_base64 = base64.b64encode(requests.get(url).content).decode()

messages = [
    {
        "role": "user",
        "content": [
            {"type": "text", "text": "Describe the video in detail."},
            {
                "type": "video_url",
                "video_url": {
                    "url": f"data:video/mp4;base64,{video_base64}"
                },
            },
        ],
    }
]

response = client.chat.completions.create(
    model="kimi-k2.5",
    messages=messages
)
```

## 배포 및 접근성

### 접근 방법

| 접근 방법 | 설명 |
|----------|------|
| Kimi.com | 웹 기반 채팅 인터페이스 |
| API | 입력 $0.60/M 토큰, 출력 $3/M 토큰 |
| Kimi Code CLI | 코딩 특화 CLI 도구 |
| HuggingFace | 모델 가중치 직접 다운로드 |
| NVIDIA NIM | NVIDIA 플랫폼 배포 |

GPT-5.2 대비 약 1/20 수준의 비용으로 유사하거나 상회하는 성능을 제공한다.
Artificial Analysis Intelligence Index 기준 운영 비용은 $371로, Claude Opus 4.5나 GPT-5.2 대비 4배 이상 저렴하다.

### 권장 추론 엔진

- vLLM
- SGLang
- KTransformers

최소 요구 사항으로 transformers 4.57.1 이상이 필요하다.

### 라이선스

Modified MIT License로 공개되어 상업적 사용이 가능하다.
모델 가중치와 코드 모두 (https://huggingface.co/moonshotai/Kimi-K2.5){:target="_blank"}에서 다운로드할 수 있다.

## Reference
- [Moonshot AI releases open-source Kimi K2.5 model with 1T parameters](https://siliconangle.com/2026/01/27/moonshot-ai-releases-open-source-kimi-k2-5-model-1t-parameters/)
- [moonshotai/Kimi-K2.5 - Hugging Face](https://huggingface.co/moonshotai/Kimi-K2.5)
- [Kimi K2.5 - NVIDIA NIM](https://build.nvidia.com/moonshotai/kimi-k2.5/modelcard)
- [China's Moonshot releases a new open source model Kimi K2.5 - TechCrunch](https://techcrunch.com/2026/01/27/chinas-moonshot-releases-a-new-open-source-model-kimi-k2-5-and-a-coding-agent/)
- [Moonshot's Kimi K2.5 New Leading Open-Weights Model - LinkedIn](https://www.linkedin.com/pulse/moonshots-kimi-k25-new-leading-open-weights-model-bnwrc/)
