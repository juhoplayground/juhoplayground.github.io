---
layout: post
title: AI는 모든 문제를 해결할 수 있는가?
author: 'Juho'
date: 2025-06-09 09:00:00 +0900
categories: [AI]
tags: [AI, LLM]
pin: True
toc : True
---

<style>
  th{
    font-weight: bold;
    text-align: center;
    background-color: white;
  }
  td{
    background-color: white;
  }

</style>

회사에서 경영진과 사업부는 AI를 마법의 지팡이, 실버 불릿으로 생각한다.  
더 이상 요구사항을 정리하지 않아도 되고, 시간들여 개발을 하지 않아도 AI가 알아서 모든 문제에 대한 정답을 말할거라고 기대한다.  
이론 컴퓨터 과학은 이론적, 수학적인 한계로 AI는 모든 문제를 해결할 수 없다고 이야기한다.  
AI가 모든 질문에 완벽히 답할 수 없는 이유는 컴퓨터(프로그램)의 본질적인 한계에서 비롯되기 때문이다.  

## 1. 모든 문제를 알고리즘으로 해결할 수 있을까?  
1928년, 수학자 힐베르트는 “기계적인 절차(알고리즘)로 수학적 명제의 참/거짓을 판단할 수 있는가?”라는 결정 문제를 제기했습니다.  
이는 이후 인간이 마주하는 다양한 문제들을 기계적으로 해결할 수 있는가 하는 더 넓은 논의로 이어졌습니다.  

## 2. 불완전성과 계산 불가능성  
931년, 쿠르트 괴델은 불완전성 정리를 통해 다음과 같은 사실을 증명합니다.  
```
모순이 없는 일관된 규칙 체계가 충분히 복잡하다면, 그 체계 안에는 참이지만 증명할 수 없는 명제가 반드시 존재한다.
하지만 외부적으로는 참으로 간주되는 명제가 존재한다.
```
이는 기계적인 논리(알고리즘)만으로는 모든 참/거짓을 판단할 수 없다는 것을 의미하며 기계적 판단의 한계를 드러냅니다.  

1936년 앨런 튜링은 이 논의를 더욱 구체화합니다.  
계산 가능한 문제를 정의하기 위해 튜링 머신이라는 개념을 제시했고 이는 오늘날의 컴퓨터 구조 및 알고리즘 이론의 기초가 됩니다.  
튜링 머신은 이론상 거의 모든 계산을 수행할 수 있지만 모든 문제에 대해 해결 가능성을 알려주는 일반적인 알고리즘은 존재하지 않는다는 사실을 증명했습니다.  

이러한 논의는 라이스의 정리로 확장됩니다.  
이 정리에 따르면 어떤 프로그램이 특정한 비자명한 속성을 가졌는지를 판단하는 일반적인 방법은 존재하지 않습니다.  
- 자명한 속성 : 모든 프로그램, 함수, 데이터가 항상 갖거나 어떠한 프로그램, 함수, 데이터도 갖지 않는 속성  
- 비자명한 속성 : 어떤 프로그램, 함수, 데이터는 그 속성을 가지고, 어떤 프로그램, 함수, 데이터는 그 속성을 가지지 않는 실제적 특성  


## 3. AI의 인지적 한계 – 모라벡의 역설과 중국어 방  
1988년 모라벡은 한가지 역설을 제시합니다. `인간에게 쉬운 일은 AI에게 어렵고, AI에게 쉬운 일은 인간에게 어렵다.`

또한 존 설이 제안한 중국어 방 문제는 AI가 언어를 실제로 이해하지 않고 단순히 기호 조작만 한다는 점을 지적합니다.  
겉보기엔 자연스럽게 대화하더라도 내부적으로는 의미를 파악하지 못하고 있다는 뜻입니다.  

## 4. 왜 이러한 이론적인 한계들이 적용되는가?  
오늘날의 컴퓨터는 폰 노이만 구조를 따릅니다.  
이는 튜링 머신을 하드웨어화한 구조로 메모리, CPU, 프로그램으로 구성되어 있습니다.  
우리가 사용하는 프로그래밍 언어나 AI 시스템도 이 기반 위에서 작동하며 결국 튜링 머신의 이론적 한계에서 자유롭지 않습니다.  
AI는 결국 컴퓨터 프로그램이며 우리가 정의한 데이터, 알고리즘, 수학적 최적화를 통해 작동합니다.  

## 5. 결론
AI는 모든 것을 스스로 처리할 수 없습니다.  
이는 계산 가능성의 한계, 논리 체계의 불완전성, 그리고 인간-기계 간 인지 차이 때문입니다.  
하지만 제한된 환경, 즉 입력이 명확하고 출력 기준이 정해진 영역에서는 수많은 연산을 빠르게 수행할 수 있기 때문에 매우 뛰어난 성능을 발휘합니다.  
그러나 현실의 문제는 대부분 모호하고, 상황에 따라 우선순위나 맥락이 달라집니다.  
이런 부분은 사람의 노력이 필요한 영역입니다.  
그래서 AI를 제대로 활용하려면 무엇을 원하는지 명확히 정의해야 합니다.  
AI를 이용한 개발에서 요구사항은 기존의 소프트웨어 개발보다 훨씬 더 명확하고 구체적이어야 합니다.  
AI는 블랙박스적인 성격이 강합니다.  
결과가 왜 그렇게 나왔는지 추론하기 어렵고 전통적인 방식처럼 코드 단위로 디버깅하기가 힘듭니다.
모호한 요구사항은 AI에게 잘못된 출력을 만들 수 있습니다.  
입력, 출력, 기준을 명확히 정의하지 않으면 AI는 사람이 의도한 방식이 아닌 "가능한 출력 중 그럴듯한 것"을 내놓게 됩니다.  


---  

AI는 **마법 지팡이**가 아니라 **강력한 추론 엔진**입니다.  
- ROI를 좌우하는 것은 **더 큰 모델**이 아니라 **더 정확한 문제 설계**입니다.  
- 라이스·괴델·튜링·라이스가 들려주는 메시지는 **완전 자동화에 대한 경고**입니다.  
- AI가 정교해질수록 사람은 **문제 정의·검증·감독** 역할로 이동해야합니다.  
이 한계를 이해할 때  AI는 비로소 **신뢰할 수 있는 파트너**가 됩니다.